# -*- coding: utf-8 -*-
"""Untitled5.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ZzzuUDVUbEB9zKdp1-19Xus6EPaBVlrg
"""

import pandas as pd

df = pd.read_csv('yield_df.csv')
print(df)

print("First 5 rows of the dataset:")
print(df.head())

"""# Get a summary of the dataset, including data types and non-null values"""

print("\nDataset Information:")
df.info()

from google.colab import drive
drive.mount('/content/drive')

# Import necessary libraries for data preparation and modeling
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
import pandas as pd

# --- Data Cleaning and Preparation (Corrected and Improved) ---

# Check if the 'Unnamed: 0' column exists and drop it if it does.
if 'Unnamed: 0' in df.columns:
    df.drop('Unnamed: 0', axis=1, inplace=True)

# Rename the yield column for clarity.
df.rename(columns={'hg/ha_yield': 'Yield'}, inplace=True)
df_cleaned = df

# Remove any rows that might have missing values.
df_cleaned.dropna(inplace=True)

# Separate features (X) and the new target (y)
X = df_cleaned.drop('Yield', axis=1)
y = df_cleaned['Yield']

# Identify categorical features that need encoding
categorical_features = ['Area', 'Item']

# Create a preprocessor
preprocessor = ColumnTransformer(
    transformers=[
        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)],
    remainder='passthrough'
)

# --- Splitting the Data ---
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print("Data has been successfully preprocessed and the unnecessary column was removed! üëç")
print(f"Training set size: {X_train.shape[0]} samples")
print(f"Testing set size: {X_test.shape[0]} samples")
print("\nHere are the columns being used as features:")
print(X_train.columns)

# Import the RandomForestRegressor model and evaluation metrics
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, r2_score

# --- Model Building ---

# Create a pipeline that first preprocesses the data and then applies the model
# A pipeline chains multiple steps together, making the workflow cleaner.
# Step 1: `preprocessor` (our OneHotEncoder for categorical features)
# Step 2: `regressor` (our Random Forest model)
model_pipeline = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('regressor', RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1))
])


# --- Model Training ---

# Train the model using our training data
# The .fit() method teaches the model the relationship between the features (X_train)
# and the target (y_train).
print("Training the Random Forest model...")
model_pipeline.fit(X_train, y_train)
print("Model training complete! üéâ")

# Import additional models to compare
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import GradientBoostingRegressor

# --- Define the models we want to compare ---
models = {
    "Linear Regression": LinearRegression(),
    "Random Forest": RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1),
    "Gradient Boosting": GradientBoostingRegressor(n_estimators=100, random_state=42)
}

# --- Train and evaluate each model ---
results = {}
for name, model in models.items():
    # Create a full pipeline for each model
    pipeline = Pipeline(steps=[
        ('preprocessor', preprocessor),
        ('regressor', model)
    ])

    # Train the model
    pipeline.fit(X_train, y_train)

    # Make predictions and evaluate
    y_pred = pipeline.predict(X_test)
    r2 = r2_score(y_test, y_pred)

    # Store the result
    results[name] = r2
    print(f"{name} training complete.")

# --- Print a summary of the results ---
print("\n--- Model Comparison ---")
for name, score in results.items():
    print(f"Model: {name:<20} | R-squared (R2) Score: {score:.4f}")

# Find and print the best model
best_model_name = max(results, key=results.get)
print(f"\nüèÜ Best performing model: {best_model_name}")



# Import matplotlib for plotting
import matplotlib.pyplot as plt
import numpy as np

# --- Make Predictions ---
# Use the trained model to make predictions on the test set
y_pred = model_pipeline.predict(X_test)


# --- Evaluate Performance ---
mae = mean_absolute_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f"\nModel Performance on Test Data:")
print(f"Mean Absolute Error (MAE): {mae:.2f}")
print(f"R-squared (R2) Score: {r2:.2f}")

# --- Visualize Results ---
# A scatter plot helps us see the relationship between actual and predicted values.
# If the points form a tight, diagonal line, it means our model is making accurate predictions.
plt.figure(figsize=(10, 6))
plt.scatter(y_test, y_pred, alpha=0.3)
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], '--', color='red', linewidth=2)
plt.xlabel("Actual Yield")
plt.ylabel("Predicted Yield")
plt.title("Actual vs. Predicted Crop Yield")
plt.grid(True)
plt.show()

import matplotlib.pyplot as plt
import pandas as pd


# --- Extract Feature Importances ---

# Get the feature names after one-hot encoding
encoded_feature_names = model_pipeline.named_steps['preprocessor'].get_feature_names_out()

# Get the importance scores from the trained regressor
importances = model_pipeline.named_steps['regressor'].feature_importances_

# Create a pandas Series for easy plotting
feature_importances = pd.Series(importances, index=encoded_feature_names).nlargest(15)

# --- Plot the Feature Importances ---
plt.figure(figsize=(12, 8))
feature_importances.plot(kind='barh', color='teal')
plt.title('Top 15 Most Important Features for Predicting Crop Yield')
plt.xlabel('Importance Score')
plt.ylabel('Feature')
plt.gca().invert_yaxis() # Display the most important feature at the top
plt.grid(axis='x', linestyle='--', alpha=0.6)
plt.show()

# Import the library for interactive widgets
import ipywidgets as widgets
from IPython.display import display, HTML

# --- Create Interactive Widgets for User Input ---

# Style for the widgets
style = {'description_width': 'initial'}

# Get unique values for dropdowns from the original dataframe
area_options = sorted(df['Area'].unique().tolist())
item_options = sorted(df['Item'].unique().tolist())

# Create the widgets
area_widget = widgets.Dropdown(options=area_options, description='Country (Area):', style=style)
item_widget = widgets.Dropdown(options=item_options, description='Crop (Item):', style=style)
rainfall_widget = widgets.FloatSlider(value=1000, min=0, max=6000, step=50, description='Avg Rainfall (mm):', style=style, readout_format='.0f')
pesticides_widget = widgets.FloatSlider(value=50, min=0, max=500, step=5, description='Pesticides (tonnes):', style=style, readout_format='.1f')
temp_widget = widgets.FloatSlider(value=15, min=-10, max=40, step=0.5, description='Avg Temp (¬∞C):', style=style, readout_format='.1f')
predict_button = widgets.Button(description="Predict Yield", button_style='success')
output_widget = widgets.Output()

def on_predict_button_clicked(b):
    with output_widget:
        output_widget.clear_output()
        # Create a DataFrame from the user's input
        input_data = pd.DataFrame({
            'Area': [area_widget.value],
            'Item': [item_widget.value],
            'Year': [2025], # Use a future year as a placeholder
            'average_rain_fall_mm_per_year': [rainfall_widget.value],
            'pesticides_tonnes': [pesticides_widget.value],
            'avg_temp': [temp_widget.value]
        })

        # Make a prediction using our trained pipeline
        prediction = model_pipeline.predict(input_data)[0]

        # Display the result
        result_html = f"<h3>Predicted Yield: <span style='color:green;'>{prediction:,.2f} hg/ha</span></h3>"
        display(HTML(result_html))


# Link the button to the function
predict_button.on_click(on_predict_button_clicked)

# --- Display the UI ---
print("üå± Crop Yield Prediction Tool")
print("Enter the conditions below and click 'Predict Yield'.")

# Arrange widgets vertically
ui = widgets.VBox([
    area_widget,
    item_widget,
    rainfall_widget,
    pesticides_widget,
    temp_widget,
    predict_button,
    output_widget
])
display(ui)

